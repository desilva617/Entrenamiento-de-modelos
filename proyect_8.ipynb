{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡Hola, Diana!  \n",
    "\n",
    "Mi nombre es Carlos Ortiz, soy code reviewer de TripleTen y voy a revisar el proyecto que acabas de desarrollar.\n",
    "\n",
    "Cuando vea un error la primera vez, lo señalaré. Deberás encontrarlo y arreglarlo. La intención es que te prepares para un espacio real de trabajo. En un trabajo, el líder de tu equipo hará lo mismo. Si no puedes solucionar el error, te daré más información en la próxima ocasión. \n",
    "\n",
    "Encontrarás mis comentarios más abajo - **por favor, no los muevas, no los modifiques ni los borres**.\n",
    "\n",
    "¿Cómo lo voy a hacer? Voy a leer detenidamente cada una de las implementaciones que has llevado a cabo para cumplir con lo solicitado. Verás los comentarios de esta forma:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "Si todo está perfecto.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "Si tu código está bien pero se puede mejorar o hay algún detalle que le hace falta.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "    \n",
    "Si de pronto hace falta algo o existe algún problema con tu código o conclusiones.\n",
    "</div>\n",
    "\n",
    "\n",
    "Puedes responderme de esta forma: \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta del estudiante</b> <a class=\"tocSkip\"></a>\n",
    "</div>\n",
    "¡Empecemos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de un modelo para analizar las terminación de contratos de los clientes de Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenido <a id='back'></a>\n",
    "\n",
    "* [Introducción](#intro)\n",
    "* [Carga de liberías y datos](#data_review)\n",
    "* [Preparación de datos](#seg)\n",
    "* [Análisis de equilibrio de clases](class)\n",
    "    * [Parámetro class_weight](#we)\n",
    "    * [Sobremuestreo](#up)\n",
    "    * [Submuestreo](#down)\n",
    "* [¿Qué modelo es mejor?](#train)\n",
    "    * [Árbol de decisión](#tree)\n",
    "    * [Bosque aleatorio](#forest)\n",
    "    * [Regresión logística](#reg)\n",
    "* [Calidad del modelo](#cal)\n",
    "* [Conclusión general](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción <a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El banco Beta Bank necesita predecir si un cliente dejará el banco pronto y se tiene los datos sobre el comportamiento pasado de los clientes y la terminación de contratos con el banco.\n",
    "Se creará un modelo con el máximo valor F1 posible, de al menos 0.59 y se verificará el F1 para el conjunto de prueba. \n",
    "Además, se medirá la métrica AUC-ROC para compararla con el valor F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de librerias y datos <a id='data_review'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar todas las librerías\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "Buen trabajo con la importación de datos y de librerías.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La característica Tenure tiene datos ausentes\n",
    "- Los nombres de las columnas no están en formato snake_case.\n",
    "- La característica que necesitamos predecir es Exited, lo cual será el objetivo. \n",
    "- Las demás columnas serán las observaciones para predecir el objetivo.\n",
    "- El objetivo es categórico ya que se predecirá si el cliente dejará o no el banco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos <a id='seg'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se cambiará el nombre de las columnas al formato snake_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rownumber', 'customerid', 'surname', 'creditscore', 'geography',\n",
       "       'gender', 'age', 'tenure', 'balance', 'numofproducts', 'hascrcard',\n",
       "       'isactivemember', 'estimatedsalary', 'exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'rownumber': 'row_number', 'customerid': 'customer_id', 'creditscore':'credit_score',\n",
    "                       'numofproducts': 'num_of_products', 'hascrcard': 'credit_card', 'isactivemember':'active_member',\n",
    "                       'estimatedsalary':'estimated_salary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_number', 'customer_id', 'surname', 'credit_score', 'geography',\n",
       "       'gender', 'age', 'tenure', 'balance', 'num_of_products', 'credit_card',\n",
       "       'active_member', 'estimated_salary', 'exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se imputarán los datos ausentes en Tenure con la mediana de la edad para no sesgar los datos.\n",
    "- Se transformará características categóricas en características numéricas mediante one-hot (OHE) usando la función get_dummies()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>surname</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>credit_card</th>\n",
       "      <th>active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>9945</td>\n",
       "      <td>15703923</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>744</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190409.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138361.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>9957</td>\n",
       "      <td>15707861</td>\n",
       "      <td>Nucci</td>\n",
       "      <td>520</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85216.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117369.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9965</td>\n",
       "      <td>15642785</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>479</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117593.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113308.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9986</td>\n",
       "      <td>15586914</td>\n",
       "      <td>Nepean</td>\n",
       "      <td>659</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_number  customer_id    surname  credit_score geography  gender  age  \\\n",
       "30            31     15589475    Azikiwe           591     Spain  Female   39   \n",
       "48            49     15766205        Yin           550   Germany    Male   38   \n",
       "51            52     15768193  Trevisani           585   Germany    Male   36   \n",
       "53            54     15702298   Parkhill           655   Germany    Male   41   \n",
       "60            61     15651280     Hunter           742   Germany    Male   35   \n",
       "...          ...          ...        ...           ...       ...     ...  ...   \n",
       "9944        9945     15703923    Cameron           744   Germany    Male   41   \n",
       "9956        9957     15707861      Nucci           520    France  Female   46   \n",
       "9964        9965     15642785    Douglas           479    France    Male   34   \n",
       "9985        9986     15586914     Nepean           659    France    Male   36   \n",
       "9999       10000     15628319     Walker           792    France  Female   28   \n",
       "\n",
       "      tenure    balance  num_of_products  credit_card  active_member  \\\n",
       "30       NaN       0.00                3            1              0   \n",
       "48       NaN  103391.38                1            0              1   \n",
       "51       NaN  146050.97                2            0              0   \n",
       "53       NaN  125561.97                1            0              0   \n",
       "60       NaN  136857.00                1            0              0   \n",
       "...      ...        ...              ...          ...            ...   \n",
       "9944     NaN  190409.34                2            1              1   \n",
       "9956     NaN   85216.61                1            1              0   \n",
       "9964     NaN  117593.48                2            0              0   \n",
       "9985     NaN  123841.49                2            1              0   \n",
       "9999     NaN  130142.79                1            1              0   \n",
       "\n",
       "      estimated_salary  exited  \n",
       "30           140469.38       1  \n",
       "48            90878.13       0  \n",
       "51            86424.57       0  \n",
       "53           164040.94       1  \n",
       "60            84509.57       0  \n",
       "...                ...     ...  \n",
       "9944         138361.48       0  \n",
       "9956         117369.52       1  \n",
       "9964         113308.29       0  \n",
       "9985          96833.00       0  \n",
       "9999          38190.78       0  \n",
       "\n",
       "[909 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = df[df['tenure'].isnull()]\n",
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    726\n",
       "1    183\n",
       "Name: exited, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter['exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_median = df.groupby('age')['tenure'].median() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def tenure_fixed(row):\n",
    "    age = row['age']\n",
    "    if pd.isna(row['tenure']):\n",
    "        return age_median[age]\n",
    "    else:\n",
    "        return row['tenure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tenure'] = df.apply(tenure_fixed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comprobacion\n",
    "df['tenure'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Determinamos las varibles de observacion y objetivo para cada conjunto de datos.\n",
    "- Como no contamos con un conjunto de prueba, se dividirán los datos fuente en proporción 3:1:1, un 60% para el conjunto de entrenamiento, 20% para el conjunto de validación y 20% para el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid_test = train_test_split(data_ohe, test_size = 0.4, random_state = 12233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid, df_test = train_test_split(df_valid_test, test_size = 0.5, random_state = 12233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables para las características y para la característica objetivo \n",
    "\n",
    "#entrenamiento\n",
    "features_train = df_train.drop(['exited'], axis=1)\n",
    "target_train = df_train['exited']\n",
    "#validacion\n",
    "features_valid = df_valid.drop(['exited'], axis=1)\n",
    "target_valid = df_valid['exited']\n",
    "#prueba\n",
    "features_test = df_test.drop(['exited'], axis=1)\n",
    "target_test = df_test['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que el algoritmo no crea que las características con mayores magnitudes y dispersión son más importantes, se estandarizará los datos con StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['row_number', 'customer_id', 'credit_score',\n",
    "       'age', 'tenure', 'balance',\n",
    "       'num_of_products', 'credit_card','active_member', 'estimated_salary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de equilibrio de clases <a id='class'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba sin técnicas de equilibrio de clases <a id='tree'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo sin equilibrio de clases, el valor F1 es muy bajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresión logística <a id='reg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.3256637168141593\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo árbol de decisión <a id='tree'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (depth = 2): 0.5027472527472528\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 5):\n",
    "        model = DecisionTreeClassifier(random_state = 12233, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions_valid = model.predict(features_valid)\n",
    "        score = f1_score(target_valid, predictions_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (depth = {}): {}\".format(best_depth, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo bosque aleatorio <a id='forest'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (n_estimators =93): 0.5144927536231885\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 100):\n",
    "    model = RandomForestClassifier(random_state=12233, n_estimators=est)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions_valid = model.predict(features_valid)  \n",
    "    score = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (n_estimators ={}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (min_samples_split =2): 0.5144927536231885\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_split = 0\n",
    "for split in range(2, 20):\n",
    "    model = RandomForestClassifier(random_state=12233, min_samples_split=split, n_estimators=93)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions_valid = model.predict(features_valid)  \n",
    "    score = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_split = split\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (min_samples_split ={}): {}\".format(best_split, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo que mejor resultado dio sin el equilibrio de clases fue el bosque aleatorio y arból de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetro class_weight <a id='we'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresión logística <a id='reg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.46673095467695275\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, class_weight = 'balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo árbol de decisión <a id='tree'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (depth = 4): 0.5441176470588236\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 5):\n",
    "        model = DecisionTreeClassifier(random_state = 12233, class_weight = 'balanced', max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        score = f1_score(target_valid, predicted_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (depth = {}): {}\".format(best_depth, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo bosque aleatorio <a id='forest'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (n_estimators =65): 0.47602131438721135\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 100):\n",
    "    model = RandomForestClassifier(random_state=12233, class_weight = 'balanced', n_estimators=est)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions_valid = model.predict(features_valid)  \n",
    "    score = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (n_estimators ={}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (min_samples_split =17): 0.6207827260458839\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_split = 0\n",
    "for split in range(2, 20):\n",
    "    model = RandomForestClassifier(random_state=12233, class_weight = 'balanced', \n",
    "                                   min_samples_split=split, n_estimators=65)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions_valid = model.predict(features_valid)  \n",
    "    score = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_split = split\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (min_samples_split ={}): {}\".format(best_split, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hiperparámetro min_samples_split auemntó el valor F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobremuestreo <a id='up'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con una función se probara la técnica de sobremuestreo para el equilibrio de clases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresión logística <a id='reg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4217298070050036\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345,solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo árbol de decisión <a id='tree'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (depth = 3): 0.422184493491794\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 5):\n",
    "        model = DecisionTreeClassifier(random_state = 12233, max_depth=depth)\n",
    "        model.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        score = f1_score(target_valid, predicted_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (depth = {}): {}\".format(best_depth, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo bosque aleatorio <a id='forest'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (n_estimators =37): 0.5895316804407713\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 65):\n",
    "    model = RandomForestClassifier(random_state=12233, n_estimators=est)\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "    predictions_valid = model.predict(features_valid)  \n",
    "    score = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (n_estimators ={}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (min_samples_split =11): 0.624390243902439\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_split = 0\n",
    "for split in range(2, 20):\n",
    "    model = RandomForestClassifier(random_state=12233, min_samples_split=split, n_estimators=37)\n",
    "    model.fit(features_upsampled, target_upsampled) \n",
    "    predictions_valid = model.predict(features_valid)  \n",
    "    score = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_split = split\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (min_samples_split ={}): {}\".format(best_split, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El hiperparámetro min_samples_split auementó el valor F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submuestreo <a id='down'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con una función se probara la técnica de submuestreo para el equilibrio de clases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresión logística <a id='reg'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.39977851605758585\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345,solver='liblinear')\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo árbol de decisión <a id='tree'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (depth = 3): 0.4378346222486616\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 5):\n",
    "        model = DecisionTreeClassifier(random_state = 12233, max_depth=depth)\n",
    "        model.fit(features_downsampled, target_downsampled)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        score = f1_score(target_valid, predicted_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (depth = {}): {}\".format(best_depth, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo bosque aleatorio <a id='forest'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (n_estimators =4): 0.4279007377598927\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 100):\n",
    "    model = RandomForestClassifier(random_state=12233, class_weight = 'balanced', n_estimators=est)\n",
    "    model.fit(features_downsampled, target_downsampled)\n",
    "    predictions_valid = model.predict(features_valid)  \n",
    "    score = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (n_estimators ={}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 del mejor modelo en el conjunto de validación (min_samples_split =2): 0.4147764095917045\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_split = 0\n",
    "for split in range(2, 20):\n",
    "    model = RandomForestClassifier(random_state=12233, min_samples_split=split, n_estimators=4)\n",
    "    model.fit(features_downsampled, target_downsampled) \n",
    "    predictions_valid = model.predict(features_valid)  \n",
    "    score = f1_score(target_valid, predictions_valid)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_split = split\n",
    "\n",
    "print(\"F1 del mejor modelo en el conjunto de validación (min_samples_split ={}): {}\".format(best_split, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La que mejor resultado dio fue incluir el parametro class_weight en balanced y el sobremuestreo.\n",
    "- El hiperparámetro min_samples_split y n_estimators mejoraron la metrica del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calidad del modelo <a id='cal'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin equilibrio de clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresión logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.48013245033112584\n",
      "Test set: 0.3182640144665461\n",
      "AUC_ROC\n",
      "Test set: 0.5015487606753861\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345,solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo árbol de decisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.5128205128205128\n",
      "Test set: 0.5149359886201992\n",
      "AUC_ROC\n",
      "Test set: 0.5233491475494814\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12233, max_depth = 2)\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 1.0\n",
      "Test set: 0.524822695035461\n",
      "AUC_ROC\n",
      "Test set: 0.5165006226650062\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12233, min_samples_split = 2, n_estimators=93)\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetro class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresión logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.6352433764633395\n",
      "Test set: 0.47450980392156866\n",
      "AUC_ROC\n",
      "Test set: 0.5054301445720679\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345,class_weight = 'balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.560145808019441\n",
      "Test set: 0.5534351145038168\n",
      "AUC_ROC\n",
      "Test set: 0.5154820754657345\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12233, class_weight = 'balanced', max_depth = 4)\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo bosque aleatorio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.9651898734177214\n",
      "Test set: 0.6090534979423868\n",
      "AUC_ROC\n",
      "Test set: 0.5294264528323356\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12233, class_weight = 'balanced', min_samples_split = 17, n_estimators=65)\n",
    "model.fit(features_train, target_train)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobremuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresión logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.5716954694068193\n",
      "Test set: 0.4268551236749117\n",
      "AUC_ROC\n",
      "Test set: 0.5061302476120639\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.3452840595697738\n",
      "Test set: 0.32705980761187786\n",
      "AUC_ROC\n",
      "Test set: 0.5241875327926366\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12233, max_depth = 3)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.9992019154030327\n",
      "Test set: 0.5836385836385836\n",
      "AUC_ROC\n",
      "Test set: 0.5246102812422957\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12233, min_samples_split = 11,n_estimators=37)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submuestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo regresión logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.4369108049311095\n",
      "Test set: 0.39799331103678925\n",
      "AUC_ROC\n",
      "Test set: 0.5070721469615844\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.4475308641975308\n",
      "Test set: 0.42957746478873243\n",
      "AUC_ROC\n",
      "Test set: 0.5241835818725464\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12233, max_depth = 4)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1\n",
      "Training set: 0.5137263247499468\n",
      "Test set: 0.4259140474663246\n",
      "AUC_ROC\n",
      "Test set: 0.5142588706057867\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12233, min_samples_split = 2, n_estimators=4)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "probabilities_valid = model.predict_proba(features_test)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('F1')\n",
    "print('Training set:', f1_score(target_train, train_predictions))\n",
    "print('Test set:', f1_score(target_test, test_predictions))\n",
    "print('AUC_ROC')\n",
    "print('Test set:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo con la métrica deseada fue bosque aleatorio con el parámetro class_weight en balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión <a id='conclusion'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusión, el mejor modelo para el conjunto de datos fue el bosque aleatorio en el cual se experimentó con los hiperparámetros, min_samples_split y n_estimators, ya que con la evaluación de solo un hiperparametro no se pudo tener el valor F1 deseado. Y la técnica que mejor resultado dio para el equilibrio de clases fue el parámetro class_weight en balanced.\n",
    "- Los hiperparámetros afectaron la calidad de predidcción.\n",
    "- Se obtuvo un valor F1 mayor a 0.59 en el conjunto de validación y de prueba.\n",
    "- El valor AUC-ROC fue mayor a la mitad a 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    " \n",
    "# Comentarios generales\n",
    "<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n",
    "    \n",
    "Espectacular trabajo, Diana. Has cumplido con todos los requerimientos y has aprobado un nuevo proyecto. ¡Felicitaciones!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
